% -*- TeX-master: "../Thesis.tex" -*-


@InProceedings{cai20:once_all,
  author       = {Han Cai and Chuang Gan and Tianzhe Wang and Zhekai Zhang and
                  Song Han},
  title        = {Once for All: Train One Network and Specialize it for
                  Efficient Deployment},
  booktitle    = {International Conference on Learning Representations},
  year         = 2020,
  month        = 4,
  annote       = {On the other hand, we denounce with righteous indignation and
                  dislike men who are so beguiled and demoralized by the charms
                  of pleasure of the moment, so blinded by desire, that they
                  cannot foresee the pain and trouble that are bound to ensue;
                  and equal blame belongs to those who fail in their duty
                  through weakness of will, which is the same as saying through
                  shrinking from toil and pain.},
  url          = {https://arxiv.org/pdf/1908.09791.pdf}
}

@InProceedings{oh19:video,
  author       = {Oh, Seoung Wug and Lee, Joon-Young and Xu, Ning and Kim, Seon
                  Joo},
  title        = {Video object segmentation using space-time memory networks},
  booktitle    = {Proceedings of the IEEE International Conference on Computer
                  Vision},
  year         = 2019,
  pages        = {9226--9235},
  month        = 4
}

@InProceedings{herrera-palacio19:video_objec_linguis_groun,
  author       = {Herrera-Palacio, Alba and Ventura, C. and Xavier
                  Gir\'{o}-i-Nieto},
  title        = {Video Object Linguistic Grounding},
  booktitle    = {ACM Multimedia Workshop on Multimodal Understanding and
                  Learning for Embodied Applications (MULEA)},
  year         = 2019,
  month        = 10,
  address      = {Nice, France},
  organization = {ACM}
}

@InProceedings{vaswani17:atten_all_you_need,
  author       = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and
                  Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and
                  Kaiser, undefinedukasz and Polosukhin, Illia},
  title        = {Attention is All You Need},
  booktitle    = {Proceedings of the 31st International Conference on Neural
                  Information Processing Systems},
  year         = 2017,
  pages        = {6000–6010},
  month        = 6,
  address      = {Red Hook, NY, USA},
  publisher    = {Curran Associates Inc.}
}

@InProceedings{yu16:unitb,
  author       = {Yu, Jiahui and Jiang, Yuning and Wang, Zhangyang and Cao,
                  Zhimin and Huang, Thomas},
  title        = {Unitbox: An Advanced Object Detection Nnetwork},
  booktitle    = {Proceedings of the 24th ACM international conference on
                  Multimedia},
  year         = 2016,
  pages        = {516--520},
  month        = 8,
  address      = {New York, NY, USA},
  publisher    = {Association for Computing Machinery}
}

@InProceedings{devlin19:bert,
  author       = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and
                  Toutanova, Kristina},
  title        = {{BERT}: Pre-training of Deep Bidirectional Transformers for
                  Language Understanding},
  booktitle    = {Proceedings of the 2019 Conference of the North {A}merican
                  Chapter of the Association for Computational Linguistics:
                  Human Language Technologies},
  year         = 2019,
  volume       = 1,
  pages        = {4171--4186},
  month        = 5,
  address      = {Minneapolis, Minnesota},
  publisher    = {Association for Computational Linguistics}
}

@InProceedings{faghri18:vse,
  author       = {Faghri, Fartash and Fleet, David J and Kiros, Jamie Ryan and
                  Fidler, Sanja},
  title        = {{VSE}++: Improving Visual-Semantic Embeddings with Hard
                  Negatives},
  booktitle    = {Proceedings of the British Machine Vision Conference ({BMVC})},
  year         = 2018,
  month        = 7,
  url          = {https://github.com/fartashf/vsepp}
}

@InProceedings{dosovitskiy21:image_worth_words,
  author       = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov
                  and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner
                  and Mostafa Dehghani and Matthias Minderer and Georg Heigold
                  and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  title        = {An Image is Worth 16x16 Words: Transformers for Image
                  Recognition at Scale},
  booktitle    = {Submitted to International Conference on Learning
                  Representations},
  year         = 2021,
  month        = 9,
}

@InProceedings{chen19:see_throug_text_group_refer_image_segmen,
  author       = {Chen, Ding-Jie and Jia, Songhao and Lo, Yi-Chen and Chen,
                  Hwann-Tzong and Liu, Tyng-Luh},
  title        = {See-Through-Text Grouping for Referring Image Segmentation},
  booktitle    = {2019 IEEE/CVF International Conference on Computer Vision
                  (ICCV)},
  year         = 2019,
  pages        = {7453-7462},
  month        = 10,
  doi          = {10.1109/ICCV.2019.00755}
}

@Article{bellver20:refvos,
  author       = {Miriam Bellver and Carles Ventura and Carina Silberer and
                  Ioannis Kazakos and Jordi Torres and Xavier Gir\'{o}-i-Nieto},
  title        = {{RefVOS}: {A} Closer Look at Referring Expressions for Video
                  Object Segmentation},
  journal      = {CoRR},
  year         = 2020,
  volume       = {abs/2010.00263},
  url          = {https://arxiv.org/abs/2010.00263},
  archiveprefix= {arXiv},
  eprint       = {2010.00263},
  timestamp    = {Mon, 12 Oct 2020 17:53:10 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2010-00263.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@Misc{enwiki:1009813550,
  author       = {{Wikipedia contributors}},
  title        = {Jaccard index --- {Wikipedia}{,} The Free Encyclopedia},
  howpublished =
                  {\url{https://en.wikipedia.org/w/index.php?title=Jaccard_index&oldid=1009813550}},
  year         = 2021,
  note         = {[Online; accessed 9 March of 2021]}
}

@Misc{enwiki:1005032489,
  author       = {{Wikipedia contributors}},
  title        = {Long short-term memory --- {Wikipedia}{,} The Free
                  Encyclopedia},
  howpublished =
                  {\url{https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&oldid=1005032489}},
  year         = 2021,
  note         = {[Online; accessed 10 March of 2021]}
}

@Article{cho14:learn_rnn,
  author       = {Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre,
                  Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk,
                  Holger and Bengio, Yoshua},
  title        = {Learning phrase representations using RNN encoder-decoder for
                  statistical machine translation},
  journal      = {arXiv preprint arXiv:1406.1078},
  year         = 2014,
  eprint       = {1406.1078},
  archiveprefix= {arXiv},
  primaryclass = {cs.CL}
}


@InProceedings{mao16:gener,
  author       = {Mao, Junhua and Huang, Jonathan and Toshev, Alexander and
                  Camburu, Oana and Yuille, Alan L and Murphy, Kevin},
  title        = {Generation and comprehension of unambiguous object
                  descriptions},
  booktitle    = {Proceedings of the IEEE conference on computer vision and
                  pattern recognition},
  year         = 2016,
  pages        = {11--20},
  eprint       = {1511.02283},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}


@InProceedings{deng09:imagen,
  author       = {J. {Deng} and W. {Dong} and R. {Socher} and L. {Li} and {Kai
                  Li} and {Li Fei-Fei}},
  title        = {ImageNet: A large-scale hierarchical image database},
  booktitle    = {2009 IEEE Conference on Computer Vision and Pattern
                  Recognition},
  year         = 2009,
  pages        = {248-255},
  month        = 6,
  abstract     = {The explosion of image data on the Internet has the potential
                  to foster more sophisticated and robust models and algorithms
                  to index, retrieve, organize and interact with images and
                  multimedia data. But exactly how such data can be harnessed
                  and organized remains a critical problem. We introduce here a
                  new database called “ImageNet”, a large-scale ontology of
                  images built upon the backbone of the WordNet
                  structure. ImageNet aims to populate the majority of the
                  80,000 synsets of WordNet with an average of 500-1000 clean
                  and full resolution images. This will result in tens of
                  millions of annotated images organized by the semantic
                  hierarchy of WordNet. This paper offers a detailed analysis
                  of ImageNet in its current state: 12 subtrees with 5247
                  synsets and 3.2 million images in total. We show that
                  ImageNet is much larger in scale and diversity and much more
                  accurate than the current image datasets. Constructing such a
                  large-scale database is a challenging task. We describe the
                  data collection scheme with Amazon Mechanical Turk. Lastly,
                  we illustrate the usefulness of ImageNet through three simple
                  applications in object recognition, image classification and
                  automatic object clustering. We hope that the scale,
                  accuracy, diversity and hierarchical structure of ImageNet
                  can offer unparalleled opportunities to researchers in the
                  computer vision community and beyond.},
  keywords     = {computer vision;image resolution;image
                  retrieval;Internet;multimedia computing;ontologies
                  (artificial intelligence);trees (mathematics);very large
                  databases;visual databases;ImageNet database;large-scale
                  hierarchical image database;Internet;image
                  retrieval;multimedia data;large-scale ontology;wordNet
                  structure;image resolution;subtree;computer
                  vision;Large-scale systems;Image
                  databases;Explosions;Internet;Robustness;Information
                  retrieval;Image retrieval;Multimedia
                  databases;Ontologies;Spine},
  doi          = {10.1109/CVPR.2009.5206848},
  issn         = {1063-6919}
}


@InProceedings{yu18:mattn,
  author       = {Yu, Licheng and Lin, Zhe and Shen, Xiaohui and Yang, Jimei
                  and Lu, Xin and Bansal, Mohit and Berg, Tamara L},
  title        = {Mattnet: Modular attention network for referring expression
                  comprehension},
  booktitle    = {Proceedings of the IEEE Conference on Computer Vision and
                  Pattern Recognition},
  year         = 2018,
  pages        = {1307--1315},
  eprint       = {1801.08186},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}


@InProceedings{liu19:improv_refer_expres_groun_cross_atten_erasin,
  author       = {Liu, Xihui and Wang, Zihao and Shao, Jing and Wang, Xiaogang
                  and Li, Hongsheng},
  title        = {Improving referring expression grounding with cross-modal
                  attention-guided erasing},
  booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and
                  Pattern Recognition},
  year         = 2019,
  pages        = {1950--1959},
  eprint       = {1903.00839},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}


@Article{qiao20:refer_expres_compr,
  author       = {Qiao, Yanyuan and Deng, Chaorui and Wu, Qi},
  title        = {Referring Expression Comprehension: A Survey of Methods and
                  Datasets},
  journal      = {IEEE Transactions on Multimedia},
  year         = 2020,
  publisher    = {IEEE},
  eprint       = {2007.09554},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}


@InProceedings{wang19:neigh,
  author       = {Wang, Peng and Wu, Qi and Cao, Jiewei and Shen, Chunhua and
                  Gao, Lianli and Hengel, Anton van den},
  title        = {Neighbourhood watch: Referring expression comprehension via
                  language-guided graph attention networks},
  booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and
                  Pattern Recognition},
  year         = 2019,
  pages        = {1960--1968},
  eprint       = {1812.04794},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}


@InProceedings{yang19:dynam,
  author       = {Yang, Sibei and Li, Guanbin and Yu, Yizhou},
  title        = {Dynamic graph attention for referring expression
                  comprehension},
  booktitle    = {Proceedings of the IEEE/CVF International Conference on
                  Computer Vision},
  year         = 2019,
  pages        = {4644--4653},
  eprint       = {1909.08164},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}


@InProceedings{yang19:cross_modal_relat_infer_groun_refer_expres,
  author       = {Yang, Sibei and Li, Guanbin and Yu, Yizhou},
  title        = {Cross-Modal Relationship Inference for Grounding Referring
                  Expressions},
  booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and
                  Pattern Recognition (CVPR)},
  year         = 2019,
  month        = 6
}


@InProceedings{cornia18:towar_cycle_consis_model_text_image_retriev,
  author       = {Cornia, Marcella and Baraldi, Lorenzo and Tavakoli, Hamed
                  R. and Cucchiara, Rita},
  title        = {Towards Cycle-Consistent Models for Text and Image Retrieval},
  booktitle    = {Proceedings of the European Conference on Computer Vision
                  (ECCV) Workshops},
  year         = 2018,
  month        = 9
}


@Misc{wiki18:max_poolin,
  author       = {Computer Science Wiki},
  title        = {Max-pooling/Pooling --- Computer Science Wiki{,}},
  year         = 2018,
  note         = {[Online; accessed 16-March-2021]},
  url          =
                  {\url{https://computersciencewiki.org/index.php?title=Max-pooling_/_Pooling&oldid=7839}}
}


@Misc{limited21:china_arduin_robot_arm,
  author       = {Alibaba Group Holding Limited},
  title        = {China Arduino Robot Arm},
  howpublished =
                  {\url{https://www.alibaba.com/countrysearch/CN/arduino-robot-arm.html}},
  month        = 3,
  year         = 2021,
  note         = {[Online; accesed 16-March-201]}
}


@Misc{iam21:futur_mater_handl,
  author       = {IAM Robotics, LLC},
  title        = {The Future of Material Handling},
  howpublished = {\url{https://www.iamrobotics.com/}},
  month        = 3,
  year         = 2021,
  note         = {[Online; accesed 16-March-201]}
}


@Misc{online21:china_no,
  author       = {Asia Times Online},
  title        = {China’s robot market is still No. 1},
  howpublished =
                  {\url{https://asiatimes.com/2019/09/chinas-robot-market-still-no-1/}},
  month        = 3,
  year         = 2021,
  note         = {[Online; accesed 16-March-201]}
}


@Misc{contributor18:artif_intel_will_replac_tasks_not_jobs,
  author       = {Joe McKendrick},
  title        = {Artificial Intelligence Will Replace Tasks, Not Jobs},
  howpublished =
                  {\url{https://www.forbes.com/sites/joemckendrick/2018/08/14/artificial-intelligence-will-replace-tasks-not-jobs/}},
  month        = 8,
  year         = 2018,
  note         = {[Online; accesed 17-March-201]}
}


@Book{nilsson09:quest_artif_intel,
  author       = {Nilsson, Nils J.},
  title        = {The Quest for Artificial Intelligence},
  publisher    = {Cambridge University Press},
  year         = 2009,
  address      = {USA},
  edition      = {1st},
  isbn         = 0521122937,
  abstract     = {Artificial intelligence (AI) is a field within computer
                  science that is attempting to build enhanced intelligence
                  into computer systems. This book traces the history of the
                  subject, from the early dreams of eighteenth-century (and
                  earlier) pioneers to the more successful work of today's AI
                  engineers. AI is becoming more and more a part of everyone's
                  life. The technology is already embedded in face-recognizing
                  cameras, speech-recognition software, Internet search
                  engines, and health-care robots, among other
                  applications. The book's many diagrams and easy-to-understand
                  descriptions of AI programs will help the casual reader gain
                  an understanding of how these and other AI systems actually
                  work. Its thorough (but unobtrusive) end-of-chapter notes
                  containing citations to important source materials will be of
                  great use to AI scholars and researchers. This book promises
                  to be the definitive history of a field that has captivated
                  the imaginations of scientists, philosophers, and writers for
                  centuries.}
}


@InProceedings{kazemzadeh14:refer_game,
  author       = {Sahar Kazemzadeh and Vicente Ordonez and Mark Matten and
                  Tamara L. Berg},
  title        = {ReferIt Game: Referring to Objects in Photographs of Natural
                  Scenes},
  booktitle    = {EMNLP},
  year         = 2014,
  month        = 10,
  url          = {http://tamaraberg.com/referitgame/}
}


@InProceedings{lin14:micros,
  author       = {Lin, Tsung-Yi and Maire, Michael and Belongie, Serge and
                  Hays, James and Perona, Pietro and Ramanan, Deva and
                  Doll{\'a}r, Piotr and Zitnick, C Lawrence},
  title        = {Microsoft {COCO}: Common objects in context},
  booktitle    = {European conference on computer vision},
  year         = 2014,
  pages        = {740--755},
  organization = {Springer},
  eprint       = {1405.0312},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}


@InProceedings{liu19:clevr,
  author       = {Liu, Runtao and Liu, Chenxi and Bai, Yutong and Yuille, Alan
                  L},
  title        = {Clevr-ref+: Diagnosing visual reasoning with referring
                  expressions},
  booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and
                  Pattern Recognition},
  year         = 2019,
  pages        = {4185--4194},
  eprint       = {1901.00850},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}


@Article{chen17:rethin,
  author       = {Chen, Liang-Chieh and Papandreou, George and Schroff, Florian
                  and Adam, Hartwig},
  title        = {Rethinking atrous convolution for semantic image
                  segmentation},
  journal      = {arXiv preprint arXiv:1706.05587},
  year         = 2017,
  eprint       = {1706.05587},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}


@Article{caudill87:neural_networ_primer_part_i,
  author       = {Caudill, Maureen},
  title        = {Neural Networks Primer, Part I},
  journal      = {AI Expert},
  year         = 1987,
  volume       = 2,
  number       = 12,
  pages        = {46–52},
  month        = dec,
  issue_date   = {Dec. 1987},
  publisher    = {Miller Freeman, Inc.},
  address      = {USA},
  issn         = {0888-3785},
  numpages     = 7
}


@InProceedings{he16:deep,
  author       = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun,
                  Jian},
  title        = {Deep residual learning for image recognition},
  booktitle    = {Proceedings of the IEEE conference on computer vision and
                  pattern recognition},
  year         = 2016,
  pages        = {770--778},
  eprint       = {1512.03385},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}


@InProceedings{glorot10:under,
  author       = {Glorot, Xavier and Bengio, Yoshua},
  title        = {Understanding the difficulty of training deep feedforward
                  neural networks.},
  booktitle    = {AISTATS},
  year         = 2010,
  editor       = {Teh, Yee Whye and Titterington, D. Mike},
  volume       = 9,
  series       = {JMLR Proceedings},
  pages        = {249-256},
  publisher    = {JMLR.org},
  added-at     = {2019-05-29T00:00:00.000+0200},
  biburl       =
                  {https://www.bibsonomy.org/bibtex/221d2d1490c8404f823f1d36b294fce72/dblp},
  ee           = {http://proceedings.mlr.press/v9/glorot10a.html},
  interhash    = {4f45a520bb65b6045bd237963ffee0ed},
  intrahash    = {21d2d1490c8404f823f1d36b294fce72},
  keywords     = {dblp},
  timestamp    = {2019-05-30T11:50:49.000+0200},
  url          =
                  {http://dblp.uni-trier.de/db/journals/jmlr/jmlrp9.html#GlorotB10}
}


@InProceedings{he15:delvin_deep_rectif,
  author       = {K. {He} and X. {Zhang} and S. {Ren} and J. {Sun}},
  title        = {Delving Deep into Rectifiers: Surpassing Human-Level
                  Performance on ImageNet Classification},
  booktitle    = {2015 IEEE International Conference on Computer Vision (ICCV)},
  year         = 2015,
  pages        = {1026-1034},
  doi          = {10.1109/ICCV.2015.123}
}


@Article{veysov20:towar_imagen_momen_speec_text,
  author       = {Veysov, Alexander},
  title        = {Toward's an ImageNet Moment for Speech-to-Text},
  journal      = {The Gradient},
  year         = 2020,
  howpublished =
                  {\url{https://thegradient.pub/towards-an-imagenet-moment-for-speech-to-text/
                  }}
}

@Misc{berners-lee21:introd_web_acces,
  author       = {Tim Berners-Lee},
  title        = {Introduction to Web Accessibility --- Accessibility in
                  Context},
  howpublished =
                  {\url{https://www.w3.org/WAI/fundamentals/accessibility-intro/}},
  year         = 2021,
  note         = {[Online; accessed 6 April of 2021]}
}


@Misc{aragon21:emiss_calcul,
  author       = {{Government of Aragon (Spain)}},
  title        = {\ch{CO2} Emission Calculator},
  howpublished = {\url{http://calcarbono.servicios4.aragon.es/}},
  year         = 2021,
  note         = {[Online; accessed 6 April of 2021]}
}


@Misc{contributors21:overf,
  author       = {{Wikipedia contributors}},
  title        = {Overfitting --- {Wikipedia}{,} The Free Encyclopedia},
  howpublished =
                  {\url{https://en.wikipedia.org/w/index.php?title=Overfitting&oldid=1016721642}},
  year         = 2021,
  note         = {[Online; accessed 9-April-2021]}
}


@Misc{brownlee28:gentl_introd_early_stopp_avoid,
  author       = {Jason Brownlee},
  title        = {A Gentle Introduction to Early Stopping to Avoid Overtraining
                  Neural Networks},
  howpublished =
                  {\url{https://machinelearningmastery.com/early-stopping-to-avoid-overtraining-neural-network-models/}},
  month        = 12,
  year         = 2028,
  note         = {[Online; accessed 9-April-2021]}
}


@InProceedings{ronneberger15:u,
  author       = {Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  title        = {U-net: Convolutional networks for biomedical image
                  segmentation},
  booktitle    = {International Conference on Medical image computing and
                  computer-assisted intervention},
  year         = 2015,
  pages        = {234--241},
  organization = {Springer},
  eprint       = {1505.04597},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}


@InProceedings{rezatofighi19:gener,
  author       = {Rezatofighi, Hamid and Tsoi, Nathan and Gwak, JunYoung and
                  Sadeghian, Amir and Reid, Ian and Savarese, Silvio},
  title        = {Generalized {I}ntersection over {U}nion: A metric and a loss
                  for bounding box regression},
  booktitle    = {Proceedings of the IEEE/CVF Conference on Computer Vision and
                  Pattern Recognition},
  year         = 2019,
  pages        = {658--666},
  month        = 6,
  eprint       = {1902.09630},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}


@Misc{contributors21:jaccar,
  author       = {{Wikipedia contributors}},
  title        = {Jaccard index --- {Wikipedia}{,} The Free Encyclopedia},
  howpublished =
                  {\url{https://en.wikipedia.org/w/index.php?title=Jaccard_index&oldid=1009813550}},
  year         = 2021,
  note         = {[Online; accessed 9-April-2021]}
}


@Article{everingham10:pascal_visual_objec_class_voc_chall,
  author       = {Everingham, M. and Van~Gool, L. and Williams, C. K. I. and
                  Winn, J. and Zisserman, A.},
  title        = {The Pascal Visual Object Classes ({VOC}) Challenge},
  journal      = {International Journal of Computer Vision},
  year         = 2010,
  volume       = 88,
  number       = 2,
  pages        = {303--338},
  month        = 6
}


@Book{gantt73:work_wages_profit_manag_histor_no,
  author       = {Henry Laurence Gantt},
  title        = {Work Wages and Profits (Management in History No 41)},
  publisher    = {Hive Publishing Company},
  year         = 1973,
  month        = 9,
  description  = {Work Wages and Profits (Management in History No 41) (Book,
                  1973)},
  isbn         = 0879600489
}


@Misc{li20:cs231,
  author       = {Fei-Fei Li and Ranjay Krishna and Danfei Xu},
  title        = {{CS231n}: Convolutional Neural Networks for Visual
                  Recognition},
  howpublished = {\url{http://cs231n.stanford.edu/}},
  year         = 2020,
  note         = {[Online; accessed 1-October-2020]}
}


@Misc{giro-i-nieto20:all_deep_learn_upc_etset_telec,
  author       = {Xavier Gir\'{o}-i-Nieto},
  title        = {All lectures on Deep Learning at UPC ETSETB TelecomBCN},
  howpublished = {\url{https://github.com/telecombcn-dl/lectures-all}},
  year         = 2020,
  note         = {[Online; accessed 1-October-2020]}
}


@Misc{ng20:machin_learn,
  author       = {Andrew Ng},
  title        = {Machine Learning --- Stanford University (via Coursera)},
  howpublished =
                  {\url{https://www.coursera.org/learn/machine-learning}},
  year         = 2020,
  note         = {[Online; accessed 1-October-2020]}
}


@Misc{ng20:deep_learn_special,
  author       = {Andrew Ng and Kian Katanforoosh and Younes Bensouda Mourri},
  title        = {Deep Learning Specialization --- {DeepLearning.AI} (via
                  Coursera)},
  howpublished = {\url{https://www.coursera.org/specializations/deep-learning}},
  year         = 2020,
  note         = {[Online; accessed 1-October-2020]}
}
