% -*- TeX-master: "../Thesis.tex" -*-


\chapter{Model} \label{cha:model}

\epigraphhead[75]{
  \epigraph{\itshape All models are wrong, but some are useful.}
  {---\scshape George E. P. Box}
}


\lettrine{E}{l} modelo.


\section{Base architecture}

En la \vref{fig:model} se muestra una representación gráfica del modelo
usado. Tiene dos partes diferenciadas con las cuales se produce la extración de
features de la parte visual y del lenguaje. Estas features son después
combiadas para conseguir un embedding \emph{multimodal} y de esta manera ser
capaz de generar la segmentación.

\begin{figure}[ht]
  \centering
  \begin{tikzpicture}
    \node[red, fill] {Test};
  \end{tikzpicture}
  \caption{TODO.}
  \label{fig:model}
\end{figure}

\subsubsection{Image encoder}
Para extraer las features de las imágenes se usa un modelo \gls{sota} llamado
DeepLab, que es una red neuronal creada por \myCite{chen17:rethin} y basada en
atrous convolutions.

TODO. Aquí hablar sobre el modelo de DeepLab.


\subsubsection{Language encoder}
TODO. Hablar aquí sobre BERT.

\subsubsection{Multimodal embedding}
TODO.


\section{Trainning}

Los diferentes modelos han sido entrenados.

\subsection{Datasets}

Para entrenar estos diferentes modelos.

\subsection{Loss functions}

Para entrenar los modelos es necesario tener unas funciones de pérdida, que
deberán ser diferenciables ya que en el proceso de optimización necesitaremos
usar las derivadas parciales de la función de pérdida respecto a los diferentes
parámetros a entrenar.

En nuestro caso, siempre trataremos con dos clases (la segmentación será una
máscara binaria).

\subsubsection{Cross Entropy}
Una de las funciones de pérdida más conocidas en la segmentación de imágenes es
la de \gls{ce}. Tenemos dos distribuciones de probabilidad

\begin{enumerate}
  \item La \textbf{predicción} puede ser \(P(\hat{Y} = 0) = \hat{p}\) or
  \(P(\hat{Y} = 1) = 1 - \hat{p}\).
  \item The \textbf{ground truth} can either be \(P(Y = 0) = p\) or
  \(P(Y = 1) = 1 - p\). Siempre se cumplirá \(p \in \{0, 1\}\).
\end{enumerate}

La función de pérdida se define entonces como
\begin{equation}
  \text{CE}(p, \hat{p}) = -(p\log\hat{p} + (1 - p)\log(1 - \hat{p})).
\end{equation}
Teniendo en cuenta que \(p \in \{0, 1\}\), la función de pérdida puede ser
reescrita de la siguiente manera,
\begin{equation}
  \text{\gls*{ce}}(p, \hat{p}) =
  \begin{cases}
    -\log(1 - \hat{p}) & p = 0 \\
    -\log\hat{p} & p = 1.
  \end{cases}
\end{equation}
Es decir, si \(p = 1\), la función de pérdida será \(0\) \gls{iff} \(\hat{p} =
1\) y será más grande cuanto más diferentes sean \(p\) y \(\hat{p}\). La
penalización crecerá exponencialmente hasta hacerse infinita para el valor
\(\hat{p} = 0\). El caso \(p = 0\) es simétrico.

A continuación se discutirán diversas variaciones de esta función de pérdida
que pueden ser útiles para entrenar diversos modelos neuronales.

\begin{itemize}
  \item \textbf{\gls*{wce}}. Es una variante de \gls{ce} en la que los ejemplos
  positivos son weighted por un coeficiente \(\beta\). Se define de la
  siguiente manera,
  \begin{equation}
    \text{\gls*{wce}}(p, \hat{p}) =
    -(\beta p\log\hat{p} + (1 - p)\log(1 - \hat{p})).
  \end{equation}
  Típicamente se usa cuando aparecen clases desequilibradas. No es demasiado
  interesante para este caso.
  \item \textbf{\gls*{bce}}. Es similar a \gls{wce} con la única diferencia que
  también se añade un peso a los ejemplos negativos. Se define de la siguiente
  manera,
  \begin{equation}
    \text{\gls*{bce}}(p, \hat{p}) =
    -(\beta p\log\hat{p} + (1 - \beta)(1 - p)\log(1 - \hat{p})).
  \end{equation}
  \item \textbf{\gls*{fl}}. Es una variante de \gls{ce} en la que se incide aún
  más en los elementos del dataset más \emph{complicados}. Estos son los que
  tienen un valor de \(\hat{p}\) intermedio entre \(0\) y \(1\). Se define de
  la siguiente manera,
  \begin{equation}
    \text{\gls*{fl}}(p, \hat{p}) =
    -(\alpha (1 - \hat{p})^\gamma p\log\hat{p} +
    (1 - \alpha)p^\gamma (1 - p)\log(1 - \hat{p})).
  \end{equation}
  Cuando \(\gamma = 0\) obtenemos \gls{bce}.
  \item \textbf{\gls*{dnc}}. TODO:
  \url{https://lars76.github.io/2018/09/27/loss-functions-for-segmentation.html} Esto
  faltaría por explicar.
\end{itemize}

\subsubsection{Overlap measures}
Otro tipo de medidades surgen con el uso de la intersección y la unión de la
segmentación predicha y el ground truth. Este tipo de funciones de pérdida nos
aportan información \emph{global}. El conocido Jaccard index o coeficiente \gls{iou},
\begin{equation}
  J(A,B) = \frac{|A \cap B|}{|A \cup B|}
  = \frac{|A \cap B|}{|A| + |B| - |A \cap B|},
\end{equation}
es típicamente usado para medir el accuracy de un modelo, pero no puede ser
usado como función de pérdida al no ser una aplicación diferenciable. Sí que
será usado para la evaluación del modelo en la \vref{sec:evaluation}

\begin{itemize}
  \item \textbf{\gls*{dil}}. Se basa en el \gls{dc}, un coeficiente similar a
  \gls{iou}, que se define de la siguiente manera,
  \begin{equation}
    \text{\gls*{dc}}(X, Y) = \frac{2|X \cap Y|}{|X| + |Y|}.
  \end{equation}
  Este dice coefficiente puede ser definido como una función de pérdida,
  \begin{equation}
    \text{\gls*{dil}}(p, \hat{p})
    = 1 - \frac{2\sum p_{h, w}\hat{p}_{h, w}}{\sum p_{h, w} + \sum \hat{p}_{h, w}},
  \end{equation}
  donde \(p_{h, w} \in \{0, 1\}\), \(0 \leq \hat{p}_{h, w} \leq 1\) y los
  sumatorios se extienden por toda la imagen en el width \(w\) y el height
  \(h\).
  \item \textbf{\gls*{ti}}. Es una generalización de \gls{dil}. Se define de la
  siguiente manera,
  \begin{equation}
    \text{\gls*{ti}}(p, \hat{p})
    = 1 - \frac{p\hat{p}}{p\hat{p} + \beta(1 - p)\hat{p} + (1 - \beta)p(1 - \hat{p})}.
  \end{equation}
  Con el valor \(\beta = \frac{1}{2}\), recuperamos la función anterior
  \gls{dil}.
\end{itemize}


\subsubsection{\gls*{iou} loss}

\cite{yu16:unitb}


\subsubsection{Combinations}
Muchas más funciones de pérdida pueden ser obtenidas por simple combinación
lineal de las anteriores. La combinación,
\begin{equation}
  \text{\gls*{ce}}(p, \hat{p}) + \text{\gls*{dil}}(p, \hat{p}),
\end{equation}
es bastante popular, ya que combina información local (\gls{ce}) con
información global (\gls{dil}).


\section{Model iterations}

1. He estado trabajando con el modelo de RefVOS, pero no he conseguido obtener
ninguna mejora significativa. Hasta ahora lo que he probado ha sido: -- Cambiar
la manera en la que se unen las neuronas que provienen de la imagen y las que
provienen del texto (en el modelo se usa multiplicación). He probado a entrenar
con suma, resta, concatenación y proyectando usando una aplicación lineal
(multiplicándolas por una matriz y luego combinándolas).  -- Probar diferentes
funciones de error: "weighted cross entropy", "balanced cross entropy", "focal
loss". Quiero probar también con otras como: "dice loss", "tversky index", "IoU
loss"...  Las variaciones que he probado partiendo de parámetros pre-entrenados
apenas varían el modelo (<1\% mejora), posiblemente porque ya esté el modelo en
cierto mínimo local de la función de error (al final son todas similares) y los
gradientes son prácticamente nulos.  Y probando variaciones con parámetros
no-entrenados no consigo llegar a la precisión de RefVOS (entreno con
train/validation/test y guardo los parámetros de la época con mejores
resultados en validación).  Por otro lado, he tratado de crear algún modelo
desde 0, sin basarme en RefVOS, pero he obtenido resultados nefastos (cercanos
a la aleatoriedad).


\section{Results}
Hey, results here.

\subsection{Numerical Evaluation} \label{sec:evaluation}

Para la evaluación del modelo se usará el concepto de intersección y de unión
entre la segmentación predecida (que es una máscara \emph{binaria}) y el ground
truth (en la \vref{fig:sets} se muestran unos diagramas con estos
conceptos).

\begin{figure}[ht]
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \caption{Union of sets \(A\) and \(B\).}
    \includesvg[width=.55\textwidth]{Union_of_sets_A_and_B.svg}
  \end{subfigure}
  \begin{subfigure}[t]{.5\textwidth}
    \centering
    \caption{Intersection of sets \(A\) and \(B\).}
    \includesvg[width=.55\textwidth]{Intersection_of_sets_A_and_B.svg}
  \end{subfigure}
  \caption[Union and intersection of sets \(A\) and \(B\)]{Graphic
    representation of union and intersection of sets \(A\) and \(B\).}
  \label{fig:sets}
\end{figure}

De aquí surge el conocido Jaccard index o coeficiente \gls{iou},
\begin{equation}
  J(A,B) = \frac{|A \cap B|}{|A \cup B|}
  = \frac{|A \cap B|}{|A| + |B| - |A \cap B|},
\end{equation}
que es típicamente usado para medir el accuracy de un modelo, pero ---como
hemos comentado anteriormente--- no puede ser usado como función de pérdida al
no ser una aplicación diferenciable.

\begin{figure}[ht]
  \begin{subfigure}[t]{.45\textwidth}
    \centering
    \caption{Bounding boxes example.}
    \includegraphics[width=.8\textwidth]{Images/Object detection Bounding Boxes.jpg}
  \end{subfigure}\hfill
  \begin{subfigure}[t]{.45\textwidth}
    \centering
    \caption{\gls{iou} visual equation.}
    \includegraphics[width=.8\textwidth]{Images/Intersection over Union.png}
  \end{subfigure}
  \caption[Explicación del Jaccard Index]{Explicación y ejemplo del Jaccard
    Index en el caso de bounding boxes.}
\end{figure}

Este índice aporta información relevante sobre cómo de ajustada está una
bounding box.\footnote{Se estudia el caso de bounding box por simplicidad, pero
  el mismo concepto aplica en el caso de segmentación pixel a pixel.} Es
evidente que el Jaccard index toma un valor entre \(0\) y \(1\), siendo \(0\)
cuando no hay intersección entre las bounding boxes y tomando el valor de \(1\)
cuando la correspondencia es exacta.

\subsection{Visual Evaluation}

Aquí mostraremos de una manera visual diferentes ejemplos y patologías
encontradas en el procesado del sistema.
