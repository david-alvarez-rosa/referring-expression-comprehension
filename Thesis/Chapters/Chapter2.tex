% -*- TeX-master: "../Thesis.tex" -*-


\chapter{Background}

\epigraphhead[75]{
  \epigraph{\itshape Begin at the beginning, the King said
    gravely, ``and go on till you come to the end: then stop.''}
  {---Lewis Carroll\\ \textit{Alice in Wonderland}}
}


\lettrine{L}{orem} ipsum dolor sit amet, consectetur
adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna
aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi
ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in
voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint
occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim
id est laborum.


\section{Fully Connected Neural networks}

A neural network, more properly referred to as an \textit{artificial} neural
network (ANN) are computing systems vaguely inspired by the biological neural
networks that constitute animal brains. Dr
\fhref{https://en.wikipedia.org/wiki/Robert_Hecht-Nielsen}{Robert Hecht-Nielsen}
(inventor of one of the first neurocomputers) defines a neural network as:

\begin{quoteBox}
  \itshape
  \ldots a computing system made up of a number of simple, highly interconnected
  processing elements, which process information by their dynamic state response
  to external inputs.
  \tcblower
  \hfill \upshape
  ---\href{https://en.wikipedia.org/wiki/Robert_Hecht-Nielsen}
  {Robert Hecht-Nielsen}
\end{quoteBox}

An ANN is based on a collection of connected units, that are called
\textit{artificial} neurons, which loosely model the neurons in a biological
brain. Each connection, like he synapses in a biological brain, can transmit a
signal to other neurons. An artificial neuron that receives a signal then
processes it and can signal neurons connected to it.


\subsubsection{Mathematical perspective}

Although the analogy made above of an ANN with a biological brain, there is no
need for this, we can just think of a neural network as a mathematical
optimization problem. We can think of the whole network to be a function that
takes some inputs to some outputs, and this function dependent on
parameters. The idea is to adjust this parameters to get a function that works
well with some known dataset, and we will trust that it will generalize well. If
the network is big enough and we carefully adjust the parameters, we will be
able to learn and calculate very complex functions.

\subsubsection{Topology}


\section{Convolutional Neural Networks}


\section{Recurrent Neural Networks}


\section{Transformers}


\section{Deep Neural Network Architectures}
