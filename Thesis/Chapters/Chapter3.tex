% -*- TeX-master: "../Thesis.tex" -*-


\chapter{Referring Expression Comprehension}

\epigraphhead[75]{
  \epigraph{\itshape Begin at the beginning, the King said
    gravely, ``and go on till you come to the end: then stop.''}
  {---\textsc{Lewis Carroll}\\ \textit{Alice in Wonderland}}
}


\lettrine{L}{anguage} ipsum dolor sit amet, consectetur
adipiscing elit, sed do eiusmod and incididunt ut labore et dolore magna
aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi
ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in
voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint
occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim
id est laborum.


\section{Problem formulation}

Hey


\section{Datasets and Evaluation}

Hey


\section{Related work}

Los métodos actuales \gls{sota} para \gls{rec} se pueden dividir en tres
grandes clases: joint embedding (see \vref{sec:joint}), modelos modulares (see
\vref{sec:modular}) and graph convolution based models (see
\vref{sec:graph}).

\subsection{Joint embedding} \label{sec:joint}
Los métodos de joint embedding son muy típicos en cualquiera de las tareas del
aprendizaje multimodal. En ellos lo que se busca es encontrar un espacio
multidimensional donde puedan ``convivir''\footnote{Este espacio
multidmensional será típicamente \(\R^n\), que es un espacio normado. Una de
las caracterísitcas deseables sería que las codificaciones de imágnes y
lenguaje similares entre ellas quedasen ``cerca'' en este espacio (en términos
de norma).} codificaciones de imagen y lenguaje en común. Esta idea viene
representada de manera gráfica en la \vref{fig:joint}.

\begin{figure}[ht]
  \centering
  \includegraphics[width=.75\textwidth]{Images/Joint.png}
  \caption[Joint embedding technique]{Joint embedding into visual-semantic
    space. Como se puede ver, las matching pairs quedan más cerca (en términos
    de norma) que las non-matching pairs en el joint space.}
  \label{fig:joint}
\end{figure}

Por tanto, aquí, para realizar \gls{rec}, lo primero que haremos es codificar
la imagen y la \gls{re} por separado en un mismo espacio vectorial. Para ello,
\gls{cnn} son muy útiles para generar representaciones de la imagen (extrayendo
las features más relevantes) y para la codificación de frases se usan \gls{rnn}
(con, por ejemplo, \gls{lstm}) y transformers.

El primer modelo de deep learning para referring expression generation and
comprehension, es de \myCite{mao16:gener}.

\subsection{Modelos modulares} \label{sec:modular}
\subsection{Graph convolution} \label{sec:graph}
