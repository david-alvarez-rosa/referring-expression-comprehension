% -*- TeX-master: "../Thesis.tex" -*-


\chapter{Referring Expression Comprehension} \label{cha:rec}

\epigraphhead[75]{
  \epigraph{\itshape We may hope that machines will eventually compete with men
    in all purely intellectual fields.}
  {---\scshape Alan Turing}
}


\lettrine{L}{anguage} ipsum dolor sit amet, consectetur
adipiscing elit, sed do eiusmod and incididunt ut labore et dolore magna
aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi
ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in
voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint
occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim
id est laborum.


\section{Problem formulation}

Hey


\section{Datasets and Evaluation}

Para el desarrollo y validación de los modelos presentados para la resolución
del problema de \gls{rec}, son necesarias dos cosas principalmente: datasets y
evaluation measures. Todo modelo neuronal necesitará de una base de datos con
la que poder entrenar (ajustar) los parámetros de los que dispone. Así mismo,
será necesario reservar parte de este dataset para poder realizar una
evaluación del mismo haciendo uso de diferentes medidas, esto es lo que hará
posible la comparación entre diferentes modelos.

En este apartado se presentarán los \emph{datasets} más importantes existentes en la
actualidad en la \vref{sec:datasets} y las \emph{evaluation measures}
más utilizadas en la \vref{sec:eval-measure}.

\subsection{Datasets} \label{sec:datasets}

Existen diferentes datasets creados exclusivamente para el entrenamiento y
evaluación de modelos neuronales creados para resolver el problema aquí
tratado.


\subsection{Evaluation measures} \label{sec:eval-measure}

Esto se corresponde con una evaluación del modelo de manera numérica. Las
diferentes evaluation measures usadas típicamente para abordar este problema
son: TODO\ldots\ldots. En la sección \vref{sec:evaluation} será explicado en
profundidad el uso de \gls{iou}.


\section{Related work}

Los métodos actuales \gls{sota} para \gls{rec} se pueden dividir en tres
grandes clases: joint embedding (see \vref{sec:joint}), modelos modulares (see
\vref{sec:modular}) and graph convolution based models (see
\vref{sec:graph}).

\subsection{Multimodal embedding} \label{sec:joint} Los métodos de multimodal
embedding son muy típicos en cualquiera de las tareas del aprendizaje
multimodal. En ellos lo que se busca es encontrar un espacio multidimensional
donde puedan ``convivir'' codificaciones de imagen y lenguaje en común. Esta
idea viene representada de manera gráfica en la \vref{fig:joint}. Este espacio
multidmensional será típicamente \(\R^n\), que es un espacio normado. Una de
las caracterísitcas deseables sería que las codificaciones de imágnes y
lenguaje similares entre ellas quedasen ``cerca'' en este espacio (en términos
de norma).

\begin{figure}[ht]
  \centering
  \includegraphics[width=.75\textwidth]{Images/Joint.png}
  \caption[Multimodal embedding technique]{Multimodal embedding into
    visual-semantic space. Como se puede ver, las matching pairs quedan más
    cerca (en términos de norma) que las non-matching pairs en el joint space.}
  \label{fig:joint}
  \source{From \cite{cornia18:towar_cycle_consis_model_text_image_retriev}}
\end{figure}

Por tanto, aquí, para realizar \gls{rec}, lo primero que haremos es codificar
la imagen y la \gls{re} por separado en un mismo espacio vectorial. Para ello,
\gls{cnn} son muy útiles para generar representaciones de la imagen (extrayendo
las features más relevantes) y para la codificación de frases se usan \gls{rnn}
(con, por ejemplo, \gls{lstm}) y transformers.

El primer modelo de deep learning para referring expression generation and
comprehension, es de \myCite{mao16:gener}, donde usan un modelo \gls{cnn} con
el que extraen las features visuales y una red de tipo \gls{lstm} para
\emph{generar} la referring expression. También da una solución para el
problema inverso de \emph{comprehension}.

Dentro de este tipo de modelos encaja el propuesto por
\myCite{bellver20:refvos} donde también se usa una red neuronal de tipo
\gls{cnn} para la codificación de la imagen, pero como codificador de lenguaje
se usa el transformer. Después para conseguir el multimodal embedding, se
convierte la frase linguistica codificada en un vector 256-dimensional y se
multiplica element-wise con las features visuales. Este modelo será estudiado
en profundidad en \vref{cha:model}.

\subsection{Modelos modulares} \label{sec:modular}
Los modelos modulares han sido usado con éxito en muchas tareas tanto en el
ámbito de \gls{cv}, como en \gls{nlp}. La técnica usada en estos casos, es la
de descomponer la \gls{re} en diferentes componentes, en los que se busca
atacar diferentes razonamientos.

\begin{figure}[ht]
  \centering
  \includegraphics[width=.75\textwidth]{Images/MattNet.png}
  \caption[\acl*{mattnet}]{\gls{mattnet}: given an expression, it is divided
    into three phrase embeddings, which are input to three visual modules that
    process the described visual region in different ways and compute
    individual matching scores.}
  \label{fig:mattnet}
  \source{From \cite{yu18:mattn}}
\end{figure}

Un ejemplo de estos modelos modulares es el presentado por \myCite{yu18:mattn},
que se encuentra representado gráficamente en la \vref{fig:mattnet}. En este
caso hay tres módulos diferenciados: el \emph{subject} module, el
\emph{location} module y el módulo de \emph{relationship}. Cada uno de ellos
computa diferentes scores, que después son usados para el cálculo de un overall
score.

Partiendo de la base de \gls{mattnet},
\myCite{liu19:improv_refer_expres_groun_cross_atten_erasin} proponen
\gls{cmatterase}, que es una estrategia de entrenamiento para este tipo de
tareas. Se base en la idea de borrar la parte más usada por el modelo de la
parte lingüistica o visual, de manera que se fuerza al modelo a aprender
estructuras más complejas\footnote{Es en parte similar a la estrategia de
  \emph{dropout} usada en el entrenamiento de fully connected neural networks,
  que se usa para evitar la dependencia en nueronas concretas y así prevenir el
  overfitting del modelo.}. Así mismo, modifica el modelo inicial
(\gls{mattnet}), considerando la imagen global como una característica más.

\subsection{Graph generation} \label{sec:graph}
En la tarea que nos concierne, es fundamental la comprensión por parte del
modelo de la \gls{re}. Este tipo de expresiones contienen diferentes objetos y
relaciones entre ellos. Es decir, es habitual referirse a un objeto no solo por
sus propiedades intrínsecas, sino también por su relación con los objetos que
lo rodean. La herramienta matemática que mejor representa este fenómeno es el
de un grafo: los nodos representan diferentes objetos y las diferentes arisas
son la relación entre objetos existente (ver \vref{fig:graph}).

\begin{figure}[ht]
  \centering
  \includegraphics[width=.75\textwidth]{Images/Graph model.png}
  \caption[Graph based model representation]{Representación resumida de los
    modelos basados en grafos. De la imagen se construye la representación en
    forma de grafo, que después es actualizada con el embedding de la expresión
    y computado un matching score entre objetos y expresión.}
  \label{fig:graph}
  \source{From \cite{qiao20:refer_expres_compr}}
\end{figure}

El uso de grafos en la tarea de \gls{rec} ha sido usado con éxito por diversos
autores. Entre ellos \myCite{wang19:neigh}, propone \gls{lgran}. Este modelo
consiste en tres modulos diferenciados: language-self attention module,
language-guided graph attention module, and matching module. El primero de
estos modulos se encarga en descomponer las \gls{re} en tres partes diferentes
(subject description, intra-class relationships, and inter-class
relationships). El modulo de language-guided graph attention es el que se
encarga de generar la representación en forma de grafo de la imagen (los nodos
que genera serán los objetos candidatos). Por último, el matching module es el
que compute el matching score entre \gls{re} y objeto (para cada uno de los
objetos candidatos).

Otros autores en explotar los grafos en este contexto son
\myCite{yang19:dynam}, que crean el modelo \gls{dga}, que permite el
razonamiento multi-step. En un comienzo, el modelo funciona igual que otros con
la generación de un grafo desde la imagen y con la mezcla de un embedding de la
expresión en el grafo. Pero a partir de aquí utilizan un módulo que llaman
``analyzer'' y que es capaz de explorar la estructura linguistica de la
\gls{re} y dividirla en una secuencia de expresiones constituyentes. De esta
manera \gls{dga} es capaz de realizar un proceso de razonamiento paso a paso
sobre estas expresiones constituyentes. Finalmente, como es común en estos
modelos (ver \vref{fig:graph}) se computa un matching score entre objetos y
expresión.

\myCite{yang19:cross_modal_relat_infer_groun_refer_expres} también crean un
modelo basado en grafos al que llaman \gls{cmrin}. Esta red consiste en un
\gls{cmre}, que se encarga de obtener la información para la construción del
grafo con ``cross-modal attention'', y de un \gls{ggcn} que usa la información
del grafo anterior y propaga la información (que es multi-modal) para poder
computar el matching score.