@InProceedings{cai20:once_all,
  author       = {Han Cai and Chuang Gan and Tianzhe Wang and Zhekai Zhang and
                  Song Han},
  title        = {Once for All: Train One Network and Specialize it for
                  Efficient Deployment},
  booktitle    = {International Conference on Learning Representations},
  year         = 2020,
  month        = 4,
  annote       = {On the other hand, we denounce with righteous indignation and
                  dislike men who are so beguiled and demoralized by the charms
                  of pleasure of the moment, so blinded by desire, that they
                  cannot foresee the pain and trouble that are bound to ensue;
                  and equal blame belongs to those who fail in their duty
                  through weakness of will, which is the same as saying through
                  shrinking from toil and pain.},
  url          = {https://arxiv.org/pdf/1908.09791.pdf}
}

@InProceedings{oh19:video,
  author       = {Oh, Seoung Wug and Lee, Joon-Young and Xu, Ning and Kim, Seon
                  Joo},
  title        = {Video object segmentation using space-time memory networks},
  booktitle    = {Proceedings of the IEEE International Conference on Computer
                  Vision},
  year         = 2019,
  pages        = {9226--9235},
  month        = 4
}

@InProceedings{herrera-palacio19:video_objec_linguis_groun,
  author       = {Herrera-Palacio, Alba and Ventura, C. and Xavier
                  Gir\'{o}-i-Nieto},
  title        = {Video Object Linguistic Grounding},
  booktitle    = {ACM Multimedia Workshop on Multimodal Understanding and
                  Learning for Embodied Applications (MULEA)},
  year         = 2019,
  month        = 10,
  address      = {Nice, France},
  organization = {ACM}
}

@InProceedings{vaswani17:atten_all_you_need,
  author       = {Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and
                  Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N. and
                  Kaiser, undefinedukasz and Polosukhin, Illia},
  title        = {Attention is All You Need},
  booktitle    = {Proceedings of the 31st International Conference on Neural
                  Information Processing Systems},
  year         = 2017,
  pages        = {6000–6010},
  month        = 6,
  address      = {Red Hook, NY, USA},
  publisher    = {Curran Associates Inc.}
}

@InProceedings{yu16:unitb,
  author       = {Yu, Jiahui and Jiang, Yuning and Wang, Zhangyang and Cao,
                  Zhimin and Huang, Thomas},
  title        = {Unitbox: An Advanced Object Detection Nnetwork},
  booktitle    = {Proceedings of the 24th ACM international conference on
                  Multimedia},
  year         = 2016,
  pages        = {516--520},
  month        = 8,
  address      = {New York, NY, USA},
  publisher    = {Association for Computing Machinery}
}

@InProceedings{devlin19:bert,
  author       = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and
                  Toutanova, Kristina},
  title        = {{BERT}: Pre-training of Deep Bidirectional Transformers for
                  Language Understanding},
  booktitle    = {Proceedings of the 2019 Conference of the North {A}merican
                  Chapter of the Association for Computational Linguistics:
                  Human Language Technologies},
  year         = 2019,
  volume       = 1,
  pages        = {4171--4186},
  month        = 5,
  address      = {Minneapolis, Minnesota},
  publisher    = {Association for Computational Linguistics}
}

@InProceedings{faghri18:vse,
  author       = {Faghri, Fartash and Fleet, David J and Kiros, Jamie Ryan and
                  Fidler, Sanja},
  title        = {{VSE}++: Improving Visual-Semantic Embeddings with Hard
                  Negatives},
  booktitle    = {Proceedings of the British Machine Vision Conference ({BMVC})},
  year         = 2018,
  month        = 7,
  url          = {https://github.com/fartashf/vsepp}
}

@InProceedings{dosovitskiy21:image_worth_words,
  author       = {Alexey Dosovitskiy and Lucas Beyer and Alexander Kolesnikov
                  and Dirk Weissenborn and Xiaohua Zhai and Thomas Unterthiner
                  and Mostafa Dehghani and Matthias Minderer and Georg Heigold
                  and Sylvain Gelly and Jakob Uszkoreit and Neil Houlsby},
  title        = {An Image is Worth 16x16 Words: Transformers for Image
                  Recognition at Scale},
  booktitle    = {Submitted to International Conference on Learning
                  Representations},
  year         = 2021,
  month        = 9,
}

@InProceedings{chen19:see_throug_text_group_refer_image_segmen,
  author       = {Chen, Ding-Jie and Jia, Songhao and Lo, Yi-Chen and Chen,
                  Hwann-Tzong and Liu, Tyng-Luh},
  title        = {See-Through-Text Grouping for Referring Image Segmentation},
  booktitle    = {2019 IEEE/CVF International Conference on Computer Vision
                  (ICCV)},
  year         = 2019,
  pages        = {7453-7462},
  month        = 10,
  doi          = {10.1109/ICCV.2019.00755}
}

@Article{bellver20:refvos,
  author       = {Miriam Bellver and Carles Ventura and Carina Silberer and
                  Ioannis Kazakos and Jordi Torres and Xavier Gir\'{o}-i-Nieto},
  title        = {{RefVOS}: {A} Closer Look at Referring Expressions for Video
                  Object Segmentation},
  journal      = {CoRR},
  year         = 2020,
  volume       = {abs/2010.00263},
  url          = {https://arxiv.org/abs/2010.00263},
  archiveprefix= {arXiv},
  eprint       = {2010.00263},
  timestamp    = {Mon, 12 Oct 2020 17:53:10 +0200},
  biburl       = {https://dblp.org/rec/journals/corr/abs-2010-00263.bib},
  bibsource    = {dblp computer science bibliography, https://dblp.org}
}

@Misc{enwiki:1009813550,
  author       = {{Wikipedia contributors}},
  title        = {Jaccard index --- {Wikipedia}{,} The Free Encyclopedia},
  howpublished =
                  {\url{https://en.wikipedia.org/w/index.php?title=Jaccard_index&oldid=1009813550}},
  year         = 2021,
  note         = {[Online; accessed 9 March of 2021]}
}

@Misc{enwiki:1005032489,
  author       = {{Wikipedia contributors}},
  title        = {Long short-term memory --- {Wikipedia}{,} The Free
                  Encyclopedia},
  howpublished =
                  {\url{https://en.wikipedia.org/w/index.php?title=Long_short-term_memory&oldid=1005032489}},
  year         = 2021,
  note         = {[Online; accessed 10 March of 2021]}
}

@Article{cho14:learn_rnn,
  author       = {Cho, Kyunghyun and Van Merri{\"e}nboer, Bart and Gulcehre,
                  Caglar and Bahdanau, Dzmitry and Bougares, Fethi and Schwenk,
                  Holger and Bengio, Yoshua},
  title        = {Learning phrase representations using RNN encoder-decoder for
                  statistical machine translation},
  journal      = {arXiv preprint arXiv:1406.1078},
  year         = 2014,
  eprint       = {1406.1078},
  archiveprefix= {arXiv},
  primaryclass = {cs.CL}
}


@InProceedings{mao16:gener,
  author       = {Mao, Junhua and Huang, Jonathan and Toshev, Alexander and
                  Camburu, Oana and Yuille, Alan L and Murphy, Kevin},
  title        = {Generation and comprehension of unambiguous object
                  descriptions},
  booktitle    = {Proceedings of the IEEE conference on computer vision and
                  pattern recognition},
  year         = 2016,
  pages        = {11--20},
  eprint       = {1511.02283},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}


@InProceedings{deng09:imagen,
  author       = {J. {Deng} and W. {Dong} and R. {Socher} and L. {Li} and {Kai
                  Li} and {Li Fei-Fei}},
  title        = {ImageNet: A large-scale hierarchical image database},
  booktitle    = {2009 IEEE Conference on Computer Vision and Pattern
                  Recognition},
  year         = 2009,
  pages        = {248-255},
  month        = {June},
  abstract     = {The explosion of image data on the Internet has the potential
                  to foster more sophisticated and robust models and algorithms
                  to index, retrieve, organize and interact with images and
                  multimedia data. But exactly how such data can be harnessed
                  and organized remains a critical problem. We introduce here a
                  new database called “ImageNet”, a large-scale ontology of
                  images built upon the backbone of the WordNet
                  structure. ImageNet aims to populate the majority of the
                  80,000 synsets of WordNet with an average of 500-1000 clean
                  and full resolution images. This will result in tens of
                  millions of annotated images organized by the semantic
                  hierarchy of WordNet. This paper offers a detailed analysis
                  of ImageNet in its current state: 12 subtrees with 5247
                  synsets and 3.2 million images in total. We show that
                  ImageNet is much larger in scale and diversity and much more
                  accurate than the current image datasets. Constructing such a
                  large-scale database is a challenging task. We describe the
                  data collection scheme with Amazon Mechanical Turk. Lastly,
                  we illustrate the usefulness of ImageNet through three simple
                  applications in object recognition, image classification and
                  automatic object clustering. We hope that the scale,
                  accuracy, diversity and hierarchical structure of ImageNet
                  can offer unparalleled opportunities to researchers in the
                  computer vision community and beyond.},
  keywords     = {computer vision;image resolution;image
                  retrieval;Internet;multimedia computing;ontologies
                  (artificial intelligence);trees (mathematics);very large
                  databases;visual databases;ImageNet database;large-scale
                  hierarchical image database;Internet;image
                  retrieval;multimedia data;large-scale ontology;wordNet
                  structure;image resolution;subtree;computer
                  vision;Large-scale systems;Image
                  databases;Explosions;Internet;Robustness;Information
                  retrieval;Image retrieval;Multimedia
                  databases;Ontologies;Spine},
  doi          = {10.1109/CVPR.2009.5206848},
  issn         = {1063-6919}
}


@InProceedings{yu18:mattn,
  author       = {Yu, Licheng and Lin, Zhe and Shen, Xiaohui and Yang, Jimei
                  and Lu, Xin and Bansal, Mohit and Berg, Tamara L},
  title        = {Mattnet: Modular attention network for referring expression
                  comprehension},
  booktitle    = {Proceedings of the IEEE Conference on Computer Vision and
                  Pattern Recognition},
  year         = 2018,
  pages        = {1307--1315},
  eprint       = {1801.08186},
  archiveprefix= {arXiv},
  primaryclass = {cs.CV}
}
}